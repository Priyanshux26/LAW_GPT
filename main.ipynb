{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3270172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-old/\n",
      "data/\n",
      "metadata/\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    config=Config(signature_version=UNSIGNED),\n",
    "    region_name=\"ap-south-1\"\n",
    ")\n",
    "\n",
    "bucket = \"indian-supreme-court-judgments\"\n",
    "\n",
    "response = s3.list_objects_v2(\n",
    "    Bucket=bucket,\n",
    "    Delimiter=\"/\"\n",
    ")\n",
    "\n",
    "for prefix in response.get(\"CommonPrefixes\", []):\n",
    "    print(prefix[\"Prefix\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "67b3e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/zip/year=2016/', 'data/zip/year=2017/', 'data/zip/year=2018/', 'data/zip/year=2019/', 'data/zip/year=2020/', 'data/zip/year=2021/', 'data/zip/year=2022/', 'data/zip/year=2023/', 'data/zip/year=2024/', 'data/zip/year=2025/']\n"
     ]
    }
   ],
   "source": [
    "response = s3.list_objects_v2(\n",
    "    Bucket=bucket,\n",
    "    Prefix=\"data/zip/\",\n",
    "    Delimiter=\"/\"\n",
    ")\n",
    "\n",
    "years = []\n",
    "for p in response.get(\"CommonPrefixes\", []):\n",
    "    years.append(p[\"Prefix\"])\n",
    "\n",
    "print(years[-10:])  # show last few years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41c1f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"data/raw/zips/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "years = [\"2023\", \"2024\"]  # adjust if latest differs\n",
    "\n",
    "for year in years:\n",
    "    key = f\"data/zip/year={year}/english.zip\"\n",
    "    local_path = os.path.join(save_dir, f\"{year}_english.zip\")\n",
    "\n",
    "    s3.download_file(bucket, key, local_path)\n",
    "    print(f\"Downloaded {year} English judgments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ccc5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2023 judgments\n",
      "Extracted 2024 judgments\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "extract_dir = \"data/raw/sc_last_2_years/\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "for year in years:\n",
    "    zip_path = f\"data/raw/zips/{year}_english.zip\"\n",
    "    out_dir = f\"{extract_dir}/{year}\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(out_dir)\n",
    "\n",
    "    print(f\"Extracted {year} judgments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980c93ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 0 cases for 2023\n",
      "Sampled 0 cases for 2024\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "final_dir = \"data/processed/sc_sampled/\"\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "SAMPLES_PER_YEAR = 300\n",
    "\n",
    "for year in years:\n",
    "    year_dir = f\"{extract_dir}/{year}\"\n",
    "    files = [f for f in os.listdir(year_dir) if f.endswith(\".json\")]\n",
    "\n",
    "    sampled = random.sample(files, min(SAMPLES_PER_YEAR, len(files)))\n",
    "\n",
    "    for file in sampled:\n",
    "        shutil.copy(\n",
    "            os.path.join(year_dir, file),\n",
    "            os.path.join(final_dir, f\"{year}_{file}\")\n",
    "        )\n",
    "\n",
    "    print(f\"Sampled {len(sampled)} cases for {year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9a471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2023:  91%|█████████▏| 780/854 [14:25<02:54,  2.35s/it]  Cannot set gray non-stroke color because /'R5823' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R5823' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R5826' is an invalid float value\n",
      "Processing 2023: 100%|██████████| 854/854 [18:43<00:00,  1.32s/it]\n",
      "Processing 2024: 100%|██████████| 782/782 [14:59<00:00,  1.15s/it]  \n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "PDF_DIR = \"data/raw/sc_last_2_years\"\n",
    "TEXT_DIR = \"data/processed/texts\"\n",
    "\n",
    "os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "for year in [\"2023\", \"2024\"]:\n",
    "    year_dir = os.path.join(PDF_DIR, year)\n",
    "\n",
    "    for root, dirs, files in os.walk(year_dir):\n",
    "        for file in tqdm(files, desc=f\"Processing {year}\"):\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                text = extract_text(pdf_path)\n",
    "\n",
    "                out_file = f\"{year}_{file.replace('.pdf', '.txt')}\"\n",
    "                with open(os.path.join(TEXT_DIR, out_file), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27b2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "TEXT_DIR = \"data/processed/texts\"\n",
    "CLEAN_DIR = \"data/processed/clean_texts\"\n",
    "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'Page \\d+ of \\d+', '', text)\n",
    "    text = re.sub(r'JUDGMENT|ORDER', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "for file in os.listdir(TEXT_DIR):\n",
    "    with open(os.path.join(TEXT_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        cleaned = clean_text(f.read())\n",
    "\n",
    "    with open(os.path.join(CLEAN_DIR, file), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1a1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhojw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bhojw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d95bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhojw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "CLEAN_DIR = \"data/processed/clean_texts\"\n",
    "os.makedirs(CHUNK_DIR, exist_ok=True)\n",
    "\n",
    "CHUNK_SIZE = 500  # words\n",
    "\n",
    "def chunk_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks, current = [], []\n",
    "\n",
    "    count = 0\n",
    "    for sent in sentences:\n",
    "        words = sent.split()\n",
    "        count += len(words)\n",
    "        current.append(sent)\n",
    "\n",
    "        if count >= CHUNK_SIZE:\n",
    "            chunks.append(\" \".join(current))\n",
    "            current, count = [], 0\n",
    "\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "for file in os.listdir(CLEAN_DIR):\n",
    "    with open(os.path.join(CLEAN_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    chunks = chunk_text(text)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(CHUNK_DIR, f\"{file}_chunk_{i}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ad5a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\lawGPT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 27551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 861/861 [07:31<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "EMB_DIR = \"data/processed/embeddings\"\n",
    "os.makedirs(EMB_DIR, exist_ok=True)\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = []\n",
    "metadata = []\n",
    "\n",
    "for file in os.listdir(CHUNK_DIR):\n",
    "    with open(os.path.join(CHUNK_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        texts.append(text)\n",
    "        metadata.append(file)\n",
    "\n",
    "print(f\"Total chunks: {len(texts)}\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "np.save(os.path.join(EMB_DIR, \"embeddings.npy\"), embeddings)\n",
    "np.save(os.path.join(EMB_DIR, \"metadata.npy\"), metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "548122da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "EMB_DIR = \"data/processed/embeddings\"\n",
    "INDEX_DIR = \"data/processed/faiss\"\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "embeddings = np.load(os.path.join(EMB_DIR, \"embeddings.npy\"))\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, os.path.join(INDEX_DIR, \"sc_judgments.index\"))\n",
    "\n",
    "print(\"FAISS index created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce2558c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matching chunks:\n",
      "2024_2024_12_492_499_EN.txt_chunk_2.txt\n",
      "2024_2024_11_2369_2374_EN.txt_chunk_0.txt\n",
      "2023_2023_15_893_902_EN.txt_chunk_4.txt\n",
      "2024_2024_8_901_915_EN.txt_chunk_8.txt\n",
      "2024_2024_10_2303_2313_EN.txt_chunk_3.txt\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "query = \"Employee terminated without notice in private company\"\n",
    "\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "index = faiss.read_index(\"data/processed/faiss/sc_judgments.index\")\n",
    "metadata = np.load(\"data/processed/embeddings/metadata.npy\", allow_pickle=True)\n",
    "\n",
    "D, I = index.search(query_embedding, k=5)\n",
    "\n",
    "print(\"Top matching chunks:\")\n",
    "for idx in I[0]:\n",
    "    print(metadata[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7f0a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "index = faiss.read_index(\"data/processed/faiss/sc_judgments.index\")\n",
    "metadata = np.load(\n",
    "    \"data/processed/embeddings/metadata.npy\",\n",
    "    allow_pickle=True\n",
    ")\n",
    "\n",
    "def retrieve_chunks(query, top_k=5):\n",
    "    query_embedding = model.encode([query])\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "\n",
    "    retrieved_texts = []\n",
    "    for idx in I[0]:\n",
    "        chunk_file = metadata[idx]\n",
    "        with open(os.path.join(CHUNK_DIR, chunk_file), \"r\", encoding=\"utf-8\") as f:\n",
    "            retrieved_texts.append(f.read())\n",
    "\n",
    "    return retrieved_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "843af9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_legal_prompt(user_case, retrieved_chunks):\n",
    "    context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal research assistant trained on Indian law.\n",
    "\n",
    "User Case Description:\n",
    "{user_case}\n",
    "\n",
    "Relevant Supreme Court Judgment Excerpts:\n",
    "{context}\n",
    "\n",
    "Tasks:\n",
    "1. Identify applicable legal principles and statutes.\n",
    "2. Explain how courts have ruled in similar cases.\n",
    "3. Provide a general legal strategy based on past judgments.\n",
    "4. Highlight common mistakes and important precautions.\n",
    "\n",
    "Important:\n",
    "- Do NOT provide legal advice.\n",
    "- Provide informational and educational guidance only.\n",
    "- Mention uncertainty where applicable.\n",
    "\n",
    "Answer clearly and concisely.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "424c893f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contract law is a set of rules and regulations that governs the creation, performance, and enforcement of contracts between two or more parties. Here's a summary of the key aspects of contract law:\n",
      "\n",
      "**Formation of a Contract**\n",
      "\n",
      "1. **Offer**: One party makes an offer to another party, which must be clear and unambiguous.\n",
      "2. **Acceptance**: The offeree accepts the offer, which must be communicated in a timely manner.\n",
      "3. **Consideration**: Both parties must provide something of value (consideration) to the other party.\n",
      "4. **Capacity**: Parties involved in a contract must have the capacity to enter into a contract (i.e., be of sound mind, be of legal age, etc.).\n",
      "5. **Legality**: The contract must not be for an illegal purpose or outcome.\n",
      "\n",
      "**Types of Contracts**\n",
      "\n",
      "1. **Express Contracts**: Written agreements between parties.\n",
      "2. **Implied Contracts**: Unwritten agreements that can be inferred from the parties' actions or circumstances.\n",
      "3. **Quasi Contracts**: Unintended obligations between parties that arise from a mistake or error.\n",
      "4. **Unilateral Contracts**: Contracts where one party makes a promise in exchange for an act.\n",
      "5. **Bilateral Contracts**: Contracts where both parties make promises to each other.\n",
      "\n",
      "**Contractual Duties**\n",
      "\n",
      "1. **Breach of Contract**: One party fails to fulfill their obligations under the contract.\n",
      "2. **Remedies**: Options for resolving disputes, including damages, rescission, and specific performance.\n",
      "3. **Conditions**: Provisions in the contract that must be satisfied before the contract becomes binding.\n",
      "\n",
      "**Defenses to Contract Enforcement**\n",
      "\n",
      "1. **Illegality**: The contract is invalid due to an illegal purpose or outcome.\n",
      "2. **Undue Influence**: One party has coercive power over another party, leading to an unfair outcome.\n",
      "3. **Mental Capacity**: One or both parties lack the capacity to enter into a contract.\n",
      "4. **Fraud**: One party misrepresents facts to induce another party to enter into a contract.\n",
      "5. **Mistake**: Both parties are unaware of a critical fact that affects the contract.\n",
      "\n",
      "**Contract Termination and Dispute Resolution**\n",
      "\n",
      "1. **Termination**: Options for ending a contract, including mutual agreement, breach of contract, and frustration.\n",
      "2. **Dispute Resolution**: Methods for resolving disputes, including negotiation, mediation, arbitration, and litigation.\n",
      "\n",
      "**Important Contract Law Terms**\n",
      "\n",
      "1. **Privity of Contract**: The parties directly involved in a contract must be aware of the terms and conditions.\n",
      "2. **Parol Evidence**: Evidence outside the contract itself that may be used to interpret the contract.\n",
      "3. **Precedent**: Prior court decisions that may be used to guide contract law.\n",
      "4. **Standing**: A party has a legitimate interest in a contract and can bring a lawsuit to enforce it.\n",
      "\n",
      "This summary provides an overview of the key aspects of contract law, including the formation of contracts, types of contracts, contractual duties, defenses to contract enforcement, and contract termination and dispute resolution.\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"llama-3.1-8b-instant\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": \"Summarize contract law\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "846773b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(prompt, model=\"llama-3.1-8b-instant\", max_tokens=500, temperature=0.2):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a legal research assistant. You DO NOT give legal advice. You only summarize patterns from judgments.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "91459c2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In Indian law, breach of contract is governed by the Indian Contract Act, 1872. Here's a summary of the key aspects:\n",
      "\n",
      "**Definition of Breach of Contract:**\n",
      "A breach of contract occurs when one party fails to perform their obligations under the contract, or performs them in a manner that is not in accordance with the terms of the contract.\n",
      "\n",
      "**Types of Breach of Contract:**\n",
      "There are two types of breach of contract:\n",
      "\n",
      "1. **Actual Breach:** This occurs when a party fails to perform their obligations under the contract.\n",
      "2. **Anticipatory Breach:** This occurs when a party indicates, before the time for performance, that they will not perform their obligations under the contract.\n",
      "\n",
      "**Consequences of Breach of Contract:**\n",
      "The consequences of breach of contract depend on the nature of the breach and the terms of the contract. Some common consequences include:\n",
      "\n",
      "1. **Damages:** The injured party may claim damages from the breaching party.\n",
      "2. **Specific Performance:** The court may order the breaching party to perform their obligations under the contract.\n",
      "3. **Cancellation:** The contract may be cancelled, and the parties may be released from their obligations.\n",
      "\n",
      "**Remedies for Breach of Contract:**\n",
      "The remedies for breach of contract are:\n",
      "\n",
      "1. **Compensatory Damages:** The injured party may claim damages to compensate for their losses.\n",
      "2. **Consequential Damages:** The injured party may claim damages for losses that were reasonably foreseeable at the time of contracting.\n",
      "3. **Nominal Damages:** The injured party may claim nominal damages, which are a small amount of money, if they have suffered no actual loss.\n",
      "\n",
      "**Burden of Proof:**\n",
      "The burden of proof lies on the party claiming breach of contract to prove that the other party has failed to perform their obligations under the contract.\n",
      "\n",
      "**Important Judgments:**\n",
      "\n",
      "1. **P. D. Hinduja & Co. Ltd. v. Veerendra Rao** (2007): This judgment held that a party's failure to perform their obligations under a contract is a breach of contract.\n",
      "2. **S. S. Builders & Engineers v. Laxmi Construction Co.** (2011): This judgment held that a party's anticipatory breach of contract is a valid ground for termination of the contract.\n",
      "\n",
      "Please note that this is a general summary and not a substitute for specific legal advice.\n"
     ]
    }
   ],
   "source": [
    "print(generate_response(\"Summarize breach of contract in Indian law.\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37aab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Structured Legal Output Prompt Builder\n",
    "\n",
    "def build_legal_prompt(user_case, retrieved_chunks):\n",
    "    \"\"\"\n",
    "    retrieved_chunks: list of tuples (chunk_text, confidence)\n",
    "    \"\"\"\n",
    "    context = \"\"\n",
    "    for txt, conf in retrieved_chunks:\n",
    "        context += f\"\\n[Confidence={round(conf,2)}]\\n{txt}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal research assistant trained on Indian Supreme Court judgments.\n",
    "You DO NOT provide legal advice. You ONLY summarize patterns.\n",
    "\n",
    "User Case Description:\n",
    "{user_case}\n",
    "\n",
    "Relevant Judgment Extracts:\n",
    "{context}\n",
    "\n",
    "Now respond in EXACTLY this structure:\n",
    "\n",
    "1. Key Legal Issues Raised\n",
    "2. Possible Applicable Acts / IPC / CrPC / Labour Codes\n",
    "3. How Supreme Court Has Handled Similar Cases\n",
    "4. General Strategic Considerations (Non-advisory)\n",
    "5. Potential Risks / Limitations\n",
    "6. Documentation Commonly Required in Such Matters\n",
    "7. Strong Disclaimer (Not Legal Advice)\n",
    "\n",
    "Start now:\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe804992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a legal research assistant trained on Indian Supreme Court judgments.\n",
      "You DO NOT provide legal advice. You ONLY summarize patterns.\n",
      "\n",
      "User Case Description:\n",
      "I was fired from my IT job.\n",
      "\n",
      "Relevant Judgment Extracts:\n",
      "\n",
      "[Confidence=0.82]\n",
      "Employer terminated without notice...\n",
      "\n",
      "\n",
      "Now respond in EXACTLY this structure:\n",
      "\n",
      "1. Key Legal Issues Raised\n",
      "2. Possible Applicable Acts / IPC / CrPC / Labour Codes\n",
      "3. How Supreme Court Has Handled Similar Cases\n",
      "4. General Strategic Considerations (Non-advisory)\n",
      "5. Potential Risks / Limitations\n",
      "6. Documentation Commonly Required in Such Matters\n",
      "7. Strong Disclaimer (Not Legal Advice)\n",
      "\n",
      "Start now:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_chunks = [(\"Employer terminated without notice...\", 0.82)]\n",
    "prompt = build_legal_prompt(\"I was fired from my IT job.\", dummy_chunks)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "399cb27c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/processed/embeddings\\\\metadata.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m CHUNK_DIR = \u001b[33m\"\u001b[39m\u001b[33mdata/processed/chunks\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Load metadata and index\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m metadata = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEMB_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata.npy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m index = faiss.read_index(INDEX_PATH)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Load embedding model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:454\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    452\u001b[39m     own_fid = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m     fid = stack.enter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    455\u001b[39m     own_fid = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    457\u001b[39m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'data/processed/embeddings\\\\metadata.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Paths already used earlier in your pipeline\n",
    "EMB_DIR = \"data/processed/embeddings\"\n",
    "INDEX_PATH = \"data/processed/faiss/sc_judgments.index\"\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "\n",
    "# Load metadata and index\n",
    "metadata = np.load(os.path.join(EMB_DIR, \"metadata.npy\"), allow_pickle=True)\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "# Load embedding model\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def retrieve_chunks(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Takes a query string, retrieves top_k legal chunks using FAISS similarity.\n",
    "    Returns a list of tuples: (text_chunk, confidence_score)\n",
    "    \"\"\"\n",
    "    query_emb = embed_model.encode([query])\n",
    "    D, I = index.search(query_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(D[0], I[0]):\n",
    "        conf = float(1 / (1 + dist))   # heuristic confidence score\n",
    "        fname = metadata[idx]          # filename of chunk\n",
    "        with open(os.path.join(CHUNK_DIR, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            chunk_text = f.read()\n",
    "        results.append((chunk_text, conf))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b1f979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You have continued to remain absent at work premises without authorisation and also you did not present yourself for our enquiry meetings called for as per our disciplinary Policy. Considering all the above, as per your agreed employment terms Clause 11, 12(V), 17, 24 & 25, your employment has been terminated with effective from the closing hours of 06 Jan 2021. […]” 5. It is evident from the above that there is no allegation whatsoever that the appellant has violated clause 19 of the appointment leading to the of termination. 6. During the pendency of disciplinary action, as the appellant was not paid his salary, he issued a legal notice for payment of wages on 29.05.2021 and filed a petition under Section 15(2) of the PW Act before the authority under the PW Act. As a counterblast, the respondent issued a notice alleging that the disputes must be settled through arbitration and proceeded to unilaterally appoint an arbitrator. We may mention here itself that even in the said reply notice dated 22.06.2021 issued by the respondent, there is no specific allegation of violation of the non-disclosure obligations by the appellant herein. The claim for arbitration naturally related to stoppage of payment of wages, which according to the appellant was within the jurisdiction of the Authority under the PW Act as per its statutory provisions. 5 “You will not give out to any one, by word of mouth or otherwise, particulars of HAEI’s business or an administrative or organizational matter of a confidential nature which may be your privilege to know by virtue of you being HAEI’’s employee.” 496 [2024] 12 S.C.R. Digital Supreme Court Reports 7. Before we deal with the facts relating to the proceedings before the Authority under the PW Act, it is necessary to mention that as the unilaterally appointed arbitrator commenced the arbitral proceedings, the appellant filed an application under Section 16 of the Act calling upon the arbitrator to rule on his competence. It is interesting to note that the arbitrator himself passed an on 01.05.2022 taking into account the decision of this Court in Perkins Eastman Architects DPC & Anr. v. HSCC (India) Ltd.6 and closing the arbitral proceedings. The relevant portion is reproduced here as follows: “[…] In the present case, as detailed herein above, the appointment of the undersigned as the Arbitrator and the Constitution of the Arbitral Tribunal thereof are without the consent or the participation of the Respondent. Once the jurisdiction of this Arbitral Tribunal has been put into question on that ground, this Tribunal ceases to have the power or authority to proceed with the matter in any manner. I therefore have no hesitation in holding that the constitution of this Arbitral Tribunal is not in accordance with or in consonance with the provisions of Section 11 of the Arbitration and Conciliation Act as amended, particularly in the light of the ratio set out by the Hon’ble Supreme Court in Perkins Eastman Architects DPC & another V/s HSCC (India) Ltd.', 0.5457050800323486), ('But, the latter part of the section excludes four classes of employees including a person employed in a supervisory capacity drawing wages exceeding Rs.10,000/- after amendment (Rs.1,600/- before amendment) per month or exercises functions mainly of a managerial nature. In this legal backdrop, let us first examine, whether the employee falls within the definition of “workman”. 12. According to the employee, he comes within the meaning of “workman” as given in section 2(s) of the I.D. Act and the management without following the legal procedure, relieved him from service abruptly and hence, the same is illegal termination. On the other hand, it was the case of the management that the nature of the duties and functions performed by the employee was in the supervisory capacity and he was drawing a salary of above Rs.1,600/- and therefore, he does not belong to the category of “workmen”. To prove their respective claims, the employee and the Senior Manager of the management were examined as W.W.1 and M.W.1; and Exts.W1 to W5 and Exts.A to D were marked before the Labour Court. 13. Evidently, the employee was appointed as Junior Engineer (E&C) with effect from 07.06.1997 under Group 3 (Admn) with a salary of Rs.4761.75 per month. Clause 14 of the appointment issued by the management makes it clear that after confirmation of the job, the termination of service will be by one month’s notice or one month’s salary in lieu of notice by either side. It is not in dispute that the posting of the employee in the cadre of Junior Engineer was 13 Substituted by Act 24 of 2010, S.2, for “one thousand six hundred rupees” (w.e.f 15-09-2010) [2024] 10 S.C.R. 2311 Lenin Kumar Ray v. M/s Express Publications (Madurai) Ltd. confirmed with effect from 07.06.1998 vide letter dated 13.07.1998. As per the letter dated 25.05.2000 of the management, the employee was promoted as Assistant Engineer (E&C) in Group 2A (Admn) with effect from 01.05.2000 and his revised salary was Rs.6008.79 per month. The services of the employee as Assistant Engineer were confirmed with effect from 01.05.2001 vide letter dated 30.04.2001 and it was categorically stated in the said letter that all other terms and conditions mentioned in the appointment dated 07.06.1997 shall continue to hold good. Vide letter dated 08.10.2003, it was informed that the services of the employee were no longer required by the management and hence, he was relieved from duty forthwith. 14. During the course of examination, the employee deposed as W.W.1 that he was not an executive cadre employee and there were senior officers to supervise and control his work. But, in the cross- examination, he asserted that he was supervising the work of two juniors who were working under him. According to M.W.1- Senior Manager of the management, the employee was an executive of the management and the management appointed two Junior Engineers and their works were being supervised by the said employee. 15. The law is well settled that the determinative factor for “workman” covered under section 2(s) of the I.D.', 0.5403051376342773)]\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_chunks(\"employment termination\", top_k=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42c03441",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieve_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Full RAG test flow inside notebook\u001b[39;00m\n\u001b[32m      3\u001b[39m user_case = \u001b[33m\"\u001b[39m\u001b[33mI was terminated from a private job without notice.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m retrieved = \u001b[43mretrieve_chunks\u001b[49m(user_case, top_k=\u001b[32m3\u001b[39m)\n\u001b[32m      6\u001b[39m prompt = build_legal_prompt(user_case, retrieved)\n\u001b[32m      8\u001b[39m response = generate_response(prompt, max_tokens=\u001b[32m350\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'retrieve_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# Full RAG test flow inside notebook\n",
    "\n",
    "user_case = \"I was terminated from a private job without notice.\"\n",
    "\n",
    "retrieved = retrieve_chunks(user_case, top_k=3)\n",
    "prompt = build_legal_prompt(user_case, retrieved)\n",
    "\n",
    "response = generate_response(prompt, max_tokens=350)\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
