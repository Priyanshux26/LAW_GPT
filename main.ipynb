{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3270172d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data-old/\n",
      "data/\n",
      "metadata/\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    config=Config(signature_version=UNSIGNED),\n",
    "    region_name=\"ap-south-1\"\n",
    ")\n",
    "\n",
    "bucket = \"indian-supreme-court-judgments\"\n",
    "\n",
    "response = s3.list_objects_v2(\n",
    "    Bucket=bucket,\n",
    "    Delimiter=\"/\"\n",
    ")\n",
    "\n",
    "for prefix in response.get(\"CommonPrefixes\", []):\n",
    "    print(prefix[\"Prefix\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67b3e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['data/zip/year=2016/', 'data/zip/year=2017/', 'data/zip/year=2018/', 'data/zip/year=2019/', 'data/zip/year=2020/', 'data/zip/year=2021/', 'data/zip/year=2022/', 'data/zip/year=2023/', 'data/zip/year=2024/', 'data/zip/year=2025/']\n"
     ]
    }
   ],
   "source": [
    "response = s3.list_objects_v2(\n",
    "    Bucket=bucket,\n",
    "    Prefix=\"data/zip/\",\n",
    "    Delimiter=\"/\"\n",
    ")\n",
    "\n",
    "years = []\n",
    "for p in response.get(\"CommonPrefixes\", []):\n",
    "    years.append(p[\"Prefix\"])\n",
    "\n",
    "print(years[-10:])  # show last few years\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b41c1f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2023 English judgments\n",
      "Downloaded 2024 English judgments\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "save_dir = \"data/raw/zips/\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "years = [\"2023\", \"2024\"]  # adjust if latest differs\n",
    "\n",
    "for year in years:\n",
    "    key = f\"data/zip/year={year}/english.zip\"\n",
    "    local_path = os.path.join(save_dir, f\"{year}_english.zip\")\n",
    "\n",
    "    s3.download_file(bucket, key, local_path)\n",
    "    print(f\"Downloaded {year} English judgments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ccc5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 2023 judgments\n",
      "Extracted 2024 judgments\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "extract_dir = \"data/raw/sc_last_2_years/\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "for year in years:\n",
    "    zip_path = f\"data/raw/zips/{year}_english.zip\"\n",
    "    out_dir = f\"{extract_dir}/{year}\"\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(out_dir)\n",
    "\n",
    "    print(f\"Extracted {year} judgments\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "980c93ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampled 0 cases for 2023\n",
      "Sampled 0 cases for 2024\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import shutil\n",
    "\n",
    "final_dir = \"data/processed/sc_sampled/\"\n",
    "os.makedirs(final_dir, exist_ok=True)\n",
    "\n",
    "SAMPLES_PER_YEAR = 300\n",
    "\n",
    "for year in years:\n",
    "    year_dir = f\"{extract_dir}/{year}\"\n",
    "    files = [f for f in os.listdir(year_dir) if f.endswith(\".json\")]\n",
    "\n",
    "    sampled = random.sample(files, min(SAMPLES_PER_YEAR, len(files)))\n",
    "\n",
    "    for file in sampled:\n",
    "        shutil.copy(\n",
    "            os.path.join(year_dir, file),\n",
    "            os.path.join(final_dir, f\"{year}_{file}\")\n",
    "        )\n",
    "\n",
    "    print(f\"Sampled {len(sampled)} cases for {year}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb9a471c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 2023:  91%|█████████▏| 780/854 [14:25<02:54,  2.35s/it]  Cannot set gray non-stroke color because /'R5823' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R5823' is an invalid float value\n",
      "Cannot set gray non-stroke color because /'R5826' is an invalid float value\n",
      "Processing 2023: 100%|██████████| 854/854 [18:43<00:00,  1.32s/it]\n",
      "Processing 2024: 100%|██████████| 782/782 [14:59<00:00,  1.15s/it]  \n"
     ]
    }
   ],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "PDF_DIR = \"data/raw/sc_last_2_years\"\n",
    "TEXT_DIR = \"data/processed/texts\"\n",
    "\n",
    "os.makedirs(TEXT_DIR, exist_ok=True)\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += page_text + \"\\n\"\n",
    "    return text\n",
    "\n",
    "for year in [\"2023\", \"2024\"]:\n",
    "    year_dir = os.path.join(PDF_DIR, year)\n",
    "\n",
    "    for root, dirs, files in os.walk(year_dir):\n",
    "        for file in tqdm(files, desc=f\"Processing {year}\"):\n",
    "            if file.lower().endswith(\".pdf\"):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                text = extract_text(pdf_path)\n",
    "\n",
    "                out_file = f\"{year}_{file.replace('.pdf', '.txt')}\"\n",
    "                with open(os.path.join(TEXT_DIR, out_file), \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d27b2ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "TEXT_DIR = \"data/processed/texts\"\n",
    "CLEAN_DIR = \"data/processed/clean_texts\"\n",
    "os.makedirs(CLEAN_DIR, exist_ok=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n+', '\\n', text)\n",
    "    text = re.sub(r'Page \\d+ of \\d+', '', text)\n",
    "    text = re.sub(r'JUDGMENT|ORDER', '', text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "for file in os.listdir(TEXT_DIR):\n",
    "    with open(os.path.join(TEXT_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        cleaned = clean_text(f.read())\n",
    "\n",
    "    with open(os.path.join(CLEAN_DIR, file), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f1a1d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhojw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\bhojw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d95bf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\bhojw\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "CLEAN_DIR = \"data/processed/clean_texts\"\n",
    "os.makedirs(CHUNK_DIR, exist_ok=True)\n",
    "\n",
    "CHUNK_SIZE = 500  # words\n",
    "\n",
    "def chunk_text(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    chunks, current = [], []\n",
    "\n",
    "    count = 0\n",
    "    for sent in sentences:\n",
    "        words = sent.split()\n",
    "        count += len(words)\n",
    "        current.append(sent)\n",
    "\n",
    "        if count >= CHUNK_SIZE:\n",
    "            chunks.append(\" \".join(current))\n",
    "            current, count = [], 0\n",
    "\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "for file in os.listdir(CLEAN_DIR):\n",
    "    with open(os.path.join(CLEAN_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "    chunks = chunk_text(text)\n",
    "\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        with open(os.path.join(CHUNK_DIR, f\"{file}_chunk_{i}.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            f.write(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "83ad5a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\lawGPT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks: 27551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 861/861 [07:31<00:00,  1.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "EMB_DIR = \"data/processed/embeddings\"\n",
    "os.makedirs(EMB_DIR, exist_ok=True)\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "texts = []\n",
    "metadata = []\n",
    "\n",
    "for file in os.listdir(CHUNK_DIR):\n",
    "    with open(os.path.join(CHUNK_DIR, file), \"r\", encoding=\"utf-8\") as f:\n",
    "        text = f.read()\n",
    "        texts.append(text)\n",
    "        metadata.append(file)\n",
    "\n",
    "print(f\"Total chunks: {len(texts)}\")\n",
    "\n",
    "embeddings = model.encode(\n",
    "    texts,\n",
    "    batch_size=32,\n",
    "    show_progress_bar=True\n",
    ")\n",
    "\n",
    "np.save(os.path.join(EMB_DIR, \"embeddings.npy\"), embeddings)\n",
    "np.save(os.path.join(EMB_DIR, \"metadata.npy\"), metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "548122da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS index created.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "EMB_DIR = \"data/processed/embeddings\"\n",
    "INDEX_DIR = \"data/processed/faiss\"\n",
    "os.makedirs(INDEX_DIR, exist_ok=True)\n",
    "\n",
    "embeddings = np.load(os.path.join(EMB_DIR, \"embeddings.npy\"))\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "faiss.write_index(index, os.path.join(INDEX_DIR, \"sc_judgments.index\"))\n",
    "\n",
    "print(\"FAISS index created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce2558c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top matching chunks:\n",
      "2024_2024_12_492_499_EN.txt_chunk_2.txt\n",
      "2024_2024_11_2369_2374_EN.txt_chunk_0.txt\n",
      "2023_2023_15_893_902_EN.txt_chunk_4.txt\n",
      "2024_2024_8_901_915_EN.txt_chunk_8.txt\n",
      "2024_2024_10_2303_2313_EN.txt_chunk_3.txt\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "query = \"Employee terminated without notice in private company\"\n",
    "\n",
    "query_embedding = model.encode([query])\n",
    "\n",
    "index = faiss.read_index(\"data/processed/faiss/sc_judgments.index\")\n",
    "metadata = np.load(\"data/processed/embeddings/metadata.npy\", allow_pickle=True)\n",
    "\n",
    "D, I = index.search(query_embedding, k=5)\n",
    "\n",
    "print(\"Top matching chunks:\")\n",
    "for idx in I[0]:\n",
    "    print(metadata[idx])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7f0a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "\n",
    "model = SentenceTransformer(MODEL_NAME)\n",
    "\n",
    "index = faiss.read_index(\"data/processed/faiss/sc_judgments.index\")\n",
    "metadata = np.load(\n",
    "    \"data/processed/embeddings/metadata.npy\",\n",
    "    allow_pickle=True\n",
    ")\n",
    "\n",
    "def retrieve_chunks(query, top_k=5):\n",
    "    query_embedding = model.encode([query])\n",
    "    D, I = index.search(query_embedding, top_k)\n",
    "\n",
    "    retrieved_texts = []\n",
    "    for idx in I[0]:\n",
    "        chunk_file = metadata[idx]\n",
    "        with open(os.path.join(CHUNK_DIR, chunk_file), \"r\", encoding=\"utf-8\") as f:\n",
    "            retrieved_texts.append(f.read())\n",
    "\n",
    "    return retrieved_texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "843af9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_legal_prompt(user_case, retrieved_chunks):\n",
    "    context = \"\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal research assistant trained on Indian law.\n",
    "\n",
    "User Case Description:\n",
    "{user_case}\n",
    "\n",
    "Relevant Supreme Court Judgment Excerpts:\n",
    "{context}\n",
    "\n",
    "Tasks:\n",
    "1. Identify applicable legal principles and statutes.\n",
    "2. Explain how courts have ruled in similar cases.\n",
    "3. Provide a general legal strategy based on past judgments.\n",
    "4. Highlight common mistakes and important precautions.\n",
    "\n",
    "Important:\n",
    "- Do NOT provide legal advice.\n",
    "- Provide informational and educational guidance only.\n",
    "- Mention uncertainty where applicable.\n",
    "\n",
    "Answer clearly and concisely.\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915ae04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\projects\\lawGPT\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/ec5deb64f2c6e6fa90c1abf74a91d5c93a9669ca/model-00002-of-00002.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1/resolve/ec5deb64f2c6e6fa90c1abf74a91d5c93a9669ca/model-00001-of-00002.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "from llama_cpp import Llama\n",
    "\n",
    "# 1. Download the model (GGUF format is optimized for CPU)\n",
    "# We use Phi-3.5 Mini which is excellent for reasoning/law tasks on laptops\n",
    "repo_id = \"microsoft/Phi-3.5-mini-instruct-gguf\"\n",
    "filename = \"Phi-3.5-mini-instruct-Q4_K_M.gguf\" # 4-bit quantized (approx 2.4 GB)\n",
    "\n",
    "print(f\"Downloading {filename} from Hugging Face... (This happens only once)\")\n",
    "model_path = hf_hub_download(repo_id=repo_id, filename=filename)\n",
    "\n",
    "# 2. Load the model efficiently\n",
    "print(\"\\nLoading model into memory...\")\n",
    "llm = Llama(\n",
    "    model_path=model_path,\n",
    "    n_ctx=4096,       # Context window (how much text it remembers)\n",
    "    n_threads=6,      # Number of CPU threads to use (adjust based on your laptop)\n",
    "    verbose=False     # Reduce logs\n",
    ")\n",
    "\n",
    "# 3. Define your LawGPT System Prompt\n",
    "system_prompt = \"\"\"You are LawGPT, a legal assistant. \n",
    "Answer the following legal question accurately, professionally, and concisely.\"\"\"\n",
    "\n",
    "def generate_legal_response(user_query):\n",
    "    # Format according to Phi-3 template\n",
    "    prompt = f\"<|system|>\\n{system_prompt}<|end|>\\n<|user|>\\n{user_query}<|end|>\\n<|assistant|>\\n\"\n",
    "    \n",
    "    output = llm(\n",
    "        prompt,\n",
    "        max_tokens=500,  # Limit response length\n",
    "        temperature=0.2, # Lower temperature = more factual/consistent for law\n",
    "        stop=[\"<|end|>\"], \n",
    "        echo=False\n",
    "    )\n",
    "    return output['choices'][0]['text']\n",
    "\n",
    "# 4. Test it\n",
    "query = \"What are the key differences between a contract and a tort?\"\n",
    "print(f\"\\nUser Query: {query}\\n\")\n",
    "print(\"LawGPT Generating response...\")\n",
    "\n",
    "response = generate_legal_response(query)\n",
    "print(\"-\" * 50)\n",
    "print(response)\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6badece",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c893f",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'The model `llama3-70b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBadRequestError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgroq\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Groq\n\u001b[32m      3\u001b[39m client = Groq(api_key=\u001b[33m\"\u001b[39m\u001b[33mgsk_t3McLImDRRS8RTxmPAkOWGdyb3FYryeAhH8587sHaSKyQ5ZAmFon\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m chat_completion = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mllama3-70b-8192\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSummarize contract law\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(chat_completion.choices[\u001b[32m0\u001b[39m].message[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:461\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, citation_options, compound_custom, disable_tool_validation, documents, exclude_domains, frequency_penalty, function_call, functions, include_domains, include_reasoning, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    242\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    243\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    300\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m    301\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    302\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    303\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    304\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    459\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    460\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m461\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    464\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    466\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    467\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcitation_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcitation_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    468\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompound_custom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompound_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    469\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdisable_tool_validation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_tool_validation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    470\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdocuments\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdocuments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    471\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    472\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    473\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    476\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_reasoning\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_reasoning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    477\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    478\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    479\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    480\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    482\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    483\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    507\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    509\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\groq\\_base_client.py:1242\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1228\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1229\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1230\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1237\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1238\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1239\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1240\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\groq\\_base_client.py:1044\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1041\u001b[39m             err.response.read()\n\u001b[32m   1043\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1046\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mBadRequestError\u001b[39m: Error code: 400 - {'error': {'message': 'The model `llama3-70b-8192` has been decommissioned and is no longer supported. Please refer to https://console.groq.com/docs/deprecations for a recommendation on which model to use instead.', 'type': 'invalid_request_error', 'code': 'model_decommissioned'}}"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "\n",
    "client = Groq(api_key=\"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\")\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"llama3-70b-8192\",\n",
    "    messages=[{\"role\":\"user\",\"content\":\"Summarize contract law\"}]\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message[\"content\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "846773b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'The model `gpt-5o-nano` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFoundError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello, summarize contract law in one sentence.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 5\u001b[39m, in \u001b[36mgenerate_response\u001b[39m\u001b[34m(prompt, max_tokens)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_response\u001b[39m(prompt, max_tokens=\u001b[32m600\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     completion = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-5o-nano\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msystem\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mYou are a legal research assistant. You DO NOT give legal advice.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m completion.choices[\u001b[32m0\u001b[39m].message[\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\openai\\_utils\\_utils.py:286\u001b[39m, in \u001b[36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m             msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[32m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py:1192\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, prompt_cache_key, prompt_cache_retention, reasoning_effort, response_format, safety_identifier, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, verbosity, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m   1145\u001b[39m \u001b[38;5;129m@required_args\u001b[39m([\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m], [\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m   1146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m   1147\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1189\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = not_given,\n\u001b[32m   1190\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m   1191\u001b[39m     validate_response_format(response_format)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1195\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m   1196\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1197\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1198\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maudio\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1199\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1200\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1203\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1204\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1205\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1206\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1207\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodalities\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1208\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1209\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1210\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprediction\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1211\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1212\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_key\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1213\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompt_cache_retention\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_cache_retention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1214\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1215\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1216\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msafety_identifier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msafety_identifier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1217\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1218\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1219\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1220\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1221\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1222\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1224\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1225\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1226\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1227\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1228\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1229\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mverbosity\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbosity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1230\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mweb_search_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1231\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1232\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsStreaming\u001b[49m\n\u001b[32m   1233\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParamsNonStreaming\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1237\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m   1238\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1239\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1240\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1241\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1242\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\openai\\_base_client.py:1259\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1245\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1246\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1247\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1254\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1255\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1256\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1257\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1258\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1259\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\lawGPT\\venv\\Lib\\site-packages\\openai\\_base_client.py:1047\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1044\u001b[39m             err.response.read()\n\u001b[32m   1046\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1047\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1049\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mNotFoundError\u001b[39m: Error code: 404 - {'error': {'message': 'The model `gpt-5o-nano` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_found'}}"
     ]
    }
   ],
   "source": [
    "generate_response(\"Hello, summarize contract law in one sentence.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e37aab47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 6: Structured Legal Output Prompt Builder\n",
    "\n",
    "def build_legal_prompt(user_case, retrieved_chunks):\n",
    "    \"\"\"\n",
    "    retrieved_chunks: list of tuples (chunk_text, confidence)\n",
    "    \"\"\"\n",
    "    context = \"\"\n",
    "    for txt, conf in retrieved_chunks:\n",
    "        context += f\"\\n[Confidence={round(conf,2)}]\\n{txt}\\n\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a legal research assistant trained on Indian Supreme Court judgments.\n",
    "You DO NOT provide legal advice. You ONLY summarize patterns.\n",
    "\n",
    "User Case Description:\n",
    "{user_case}\n",
    "\n",
    "Relevant Judgment Extracts:\n",
    "{context}\n",
    "\n",
    "Now respond in EXACTLY this structure:\n",
    "\n",
    "1. Key Legal Issues Raised\n",
    "2. Possible Applicable Acts / IPC / CrPC / Labour Codes\n",
    "3. How Supreme Court Has Handled Similar Cases\n",
    "4. General Strategic Considerations (Non-advisory)\n",
    "5. Potential Risks / Limitations\n",
    "6. Documentation Commonly Required in Such Matters\n",
    "7. Strong Disclaimer (Not Legal Advice)\n",
    "\n",
    "Start now:\n",
    "\"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe804992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a legal research assistant trained on Indian Supreme Court judgments.\n",
      "You DO NOT provide legal advice. You ONLY summarize patterns.\n",
      "\n",
      "User Case Description:\n",
      "I was fired from my IT job.\n",
      "\n",
      "Relevant Judgment Extracts:\n",
      "\n",
      "[Confidence=0.82]\n",
      "Employer terminated without notice...\n",
      "\n",
      "\n",
      "Now respond in EXACTLY this structure:\n",
      "\n",
      "1. Key Legal Issues Raised\n",
      "2. Possible Applicable Acts / IPC / CrPC / Labour Codes\n",
      "3. How Supreme Court Has Handled Similar Cases\n",
      "4. General Strategic Considerations (Non-advisory)\n",
      "5. Potential Risks / Limitations\n",
      "6. Documentation Commonly Required in Such Matters\n",
      "7. Strong Disclaimer (Not Legal Advice)\n",
      "\n",
      "Start now:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_chunks = [(\"Employer terminated without notice...\", 0.82)]\n",
    "prompt = build_legal_prompt(\"I was fired from my IT job.\", dummy_chunks)\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "399cb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Paths already used earlier in your pipeline\n",
    "EMB_DIR = \"data/processed/embeddings\"\n",
    "INDEX_PATH = \"data/processed/faiss/sc_judgments.index\"\n",
    "CHUNK_DIR = \"data/processed/chunks\"\n",
    "\n",
    "# Load metadata and index\n",
    "metadata = np.load(os.path.join(EMB_DIR, \"metadata.npy\"), allow_pickle=True)\n",
    "index = faiss.read_index(INDEX_PATH)\n",
    "\n",
    "# Load embedding model\n",
    "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "def retrieve_chunks(query, top_k=3):\n",
    "    \"\"\"\n",
    "    Takes a query string, retrieves top_k legal chunks using FAISS similarity.\n",
    "    Returns a list of tuples: (text_chunk, confidence_score)\n",
    "    \"\"\"\n",
    "    query_emb = embed_model.encode([query])\n",
    "    D, I = index.search(query_emb, top_k)\n",
    "\n",
    "    results = []\n",
    "    for dist, idx in zip(D[0], I[0]):\n",
    "        conf = float(1 / (1 + dist))   # heuristic confidence score\n",
    "        fname = metadata[idx]          # filename of chunk\n",
    "        with open(os.path.join(CHUNK_DIR, fname), \"r\", encoding=\"utf-8\") as f:\n",
    "            chunk_text = f.read()\n",
    "        results.append((chunk_text, conf))\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b1f979f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('You have continued to remain absent at work premises without authorisation and also you did not present yourself for our enquiry meetings called for as per our disciplinary Policy. Considering all the above, as per your agreed employment terms Clause 11, 12(V), 17, 24 & 25, your employment has been terminated with effective from the closing hours of 06 Jan 2021. […]” 5. It is evident from the above that there is no allegation whatsoever that the appellant has violated clause 19 of the appointment leading to the of termination. 6. During the pendency of disciplinary action, as the appellant was not paid his salary, he issued a legal notice for payment of wages on 29.05.2021 and filed a petition under Section 15(2) of the PW Act before the authority under the PW Act. As a counterblast, the respondent issued a notice alleging that the disputes must be settled through arbitration and proceeded to unilaterally appoint an arbitrator. We may mention here itself that even in the said reply notice dated 22.06.2021 issued by the respondent, there is no specific allegation of violation of the non-disclosure obligations by the appellant herein. The claim for arbitration naturally related to stoppage of payment of wages, which according to the appellant was within the jurisdiction of the Authority under the PW Act as per its statutory provisions. 5 “You will not give out to any one, by word of mouth or otherwise, particulars of HAEI’s business or an administrative or organizational matter of a confidential nature which may be your privilege to know by virtue of you being HAEI’’s employee.” 496 [2024] 12 S.C.R. Digital Supreme Court Reports 7. Before we deal with the facts relating to the proceedings before the Authority under the PW Act, it is necessary to mention that as the unilaterally appointed arbitrator commenced the arbitral proceedings, the appellant filed an application under Section 16 of the Act calling upon the arbitrator to rule on his competence. It is interesting to note that the arbitrator himself passed an on 01.05.2022 taking into account the decision of this Court in Perkins Eastman Architects DPC & Anr. v. HSCC (India) Ltd.6 and closing the arbitral proceedings. The relevant portion is reproduced here as follows: “[…] In the present case, as detailed herein above, the appointment of the undersigned as the Arbitrator and the Constitution of the Arbitral Tribunal thereof are without the consent or the participation of the Respondent. Once the jurisdiction of this Arbitral Tribunal has been put into question on that ground, this Tribunal ceases to have the power or authority to proceed with the matter in any manner. I therefore have no hesitation in holding that the constitution of this Arbitral Tribunal is not in accordance with or in consonance with the provisions of Section 11 of the Arbitration and Conciliation Act as amended, particularly in the light of the ratio set out by the Hon’ble Supreme Court in Perkins Eastman Architects DPC & another V/s HSCC (India) Ltd.', 0.5457050800323486), ('But, the latter part of the section excludes four classes of employees including a person employed in a supervisory capacity drawing wages exceeding Rs.10,000/- after amendment (Rs.1,600/- before amendment) per month or exercises functions mainly of a managerial nature. In this legal backdrop, let us first examine, whether the employee falls within the definition of “workman”. 12. According to the employee, he comes within the meaning of “workman” as given in section 2(s) of the I.D. Act and the management without following the legal procedure, relieved him from service abruptly and hence, the same is illegal termination. On the other hand, it was the case of the management that the nature of the duties and functions performed by the employee was in the supervisory capacity and he was drawing a salary of above Rs.1,600/- and therefore, he does not belong to the category of “workmen”. To prove their respective claims, the employee and the Senior Manager of the management were examined as W.W.1 and M.W.1; and Exts.W1 to W5 and Exts.A to D were marked before the Labour Court. 13. Evidently, the employee was appointed as Junior Engineer (E&C) with effect from 07.06.1997 under Group 3 (Admn) with a salary of Rs.4761.75 per month. Clause 14 of the appointment issued by the management makes it clear that after confirmation of the job, the termination of service will be by one month’s notice or one month’s salary in lieu of notice by either side. It is not in dispute that the posting of the employee in the cadre of Junior Engineer was 13 Substituted by Act 24 of 2010, S.2, for “one thousand six hundred rupees” (w.e.f 15-09-2010) [2024] 10 S.C.R. 2311 Lenin Kumar Ray v. M/s Express Publications (Madurai) Ltd. confirmed with effect from 07.06.1998 vide letter dated 13.07.1998. As per the letter dated 25.05.2000 of the management, the employee was promoted as Assistant Engineer (E&C) in Group 2A (Admn) with effect from 01.05.2000 and his revised salary was Rs.6008.79 per month. The services of the employee as Assistant Engineer were confirmed with effect from 01.05.2001 vide letter dated 30.04.2001 and it was categorically stated in the said letter that all other terms and conditions mentioned in the appointment dated 07.06.1997 shall continue to hold good. Vide letter dated 08.10.2003, it was informed that the services of the employee were no longer required by the management and hence, he was relieved from duty forthwith. 14. During the course of examination, the employee deposed as W.W.1 that he was not an executive cadre employee and there were senior officers to supervise and control his work. But, in the cross- examination, he asserted that he was supervising the work of two juniors who were working under him. According to M.W.1- Senior Manager of the management, the employee was an executive of the management and the management appointed two Junior Engineers and their works were being supervised by the said employee. 15. The law is well settled that the determinative factor for “workman” covered under section 2(s) of the I.D.', 0.5403051376342773)]\n"
     ]
    }
   ],
   "source": [
    "print(retrieve_chunks(\"employment termination\", top_k=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42c03441",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2673 > 2048). Running this sequence through the model will result in indexing errors\n",
      "This is a friendly reminder - the current text generation call has exceeded the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a legal research assistant trained on Indian Supreme Court judgments.\n",
      "You DO NOT provide legal advice. You ONLY summarize patterns.\n",
      "\n",
      "User Case Description:\n",
      "I was terminated from a private job without notice.\n",
      "\n",
      "Relevant Judgment Extracts:\n",
      "\n",
      "[Confidence=0.51]\n",
      "You have continued to remain absent at work premises without authorisation and also you did not present yourself for our enquiry meetings called for as per our disciplinary Policy. Considering all the above, as per your agreed employment terms Clause 11, 12(V), 17, 24 & 25, your employment has been terminated with effective from the closing hours of 06 Jan 2021. […]” 5. It is evident from the above that there is no allegation whatsoever that the appellant has violated clause 19 of the appointment leading to the of termination. 6. During the pendency of disciplinary action, as the appellant was not paid his salary, he issued a legal notice for payment of wages on 29.05.2021 and filed a petition under Section 15(2) of the PW Act before the authority under the PW Act. As a counterblast, the respondent issued a notice alleging that the disputes must be settled through arbitration and proceeded to unilaterally appoint an arbitrator. We may mention here itself that even in the said reply notice dated 22.06.2021 issued by the respondent, there is no specific allegation of violation of the non-disclosure obligations by the appellant herein. The claim for arbitration naturally related to stoppage of payment of wages, which according to the appellant was within the jurisdiction of the Authority under the PW Act as per its statutory provisions. 5 “You will not give out to any one, by word of mouth or otherwise, particulars of HAEI’s business or an administrative or organizational matter of a confidential nature which may be your privilege to know by virtue of you being HAEI’’s employee.” 496 [2024] 12 S.C.R. Digital Supreme Court Reports 7. Before we deal with the facts relating to the proceedings before the Authority under the PW Act, it is necessary to mention that as the unilaterally appointed arbitrator commenced the arbitral proceedings, the appellant filed an application under Section 16 of the Act calling upon the arbitrator to rule on his competence. It is interesting to note that the arbitrator himself passed an on 01.05.2022 taking into account the decision of this Court in Perkins Eastman Architects DPC & Anr. v. HSCC (India) Ltd.6 and closing the arbitral proceedings. The relevant portion is reproduced here as follows: “[…] In the present case, as detailed herein above, the appointment of the undersigned as the Arbitrator and the Constitution of the Arbitral Tribunal thereof are without the consent or the participation of the Respondent. Once the jurisdiction of this Arbitral Tribunal has been put into question on that ground, this Tribunal ceases to have the power or authority to proceed with the matter in any manner. I therefore have no hesitation in holding that the constitution of this Arbitral Tribunal is not in accordance with or in consonance with the provisions of Section 11 of the Arbitration and Conciliation Act as amended, particularly in the light of the ratio set out by the Hon’ble Supreme Court in Perkins Eastman Architects DPC & another V/s HSCC (India) Ltd.\n",
      "\n",
      "[Confidence=0.48]\n",
      "[2024] 11 S.C.R. 2369 : 2024 INSC 870 Life Insurance Corporation of India & Ors. v. Om Parkash (Civil Appeal No(s). 4393 of 2010) 13 November 2024 [Hrishikesh Roy* and S.V.N. Bhatti, JJ.] Issue for Consideration Whether the High Court erred in granting relief to the employee by setting aside his termination for abandonment of service despite the employee's failure to disclose his subsequent employment and the procedural compliance by the employer under Regulation 39(4)(iii) of the LIC Staff Regulations, 1960. Headnotes† Regulation 39(4)(iii), LIC Staff Regulations, 1960 – Abandonment of Service – The regulation deems an employee to have abandoned service if absent for 90 consecutive days without intimation – Employee absented himself without informing the employer, and notices were issued to his recorded address – The High Court overlooked the Respondent's abandonment of service and suppressed subsequent employment. [Para 11] Constitution of India – Article 226 – Equitable Relief – Relief under Article 226 is equitable and requires the petitioner to approach the court with clean hands – Employee, during the pendency of the dispute, secured employment with the Food Corporation of India (FCI) but concealed this fact from the court and employer – Suppression of subsequent employment disentitled the employee to equitable relief [Paras 10, 12]. Service of Notice – Procedural compliance under Regulation 39(4)(iii), LIC Staff Regulations, 1960 – Regulation 39(4) (iii) permits service of notices by registered post to the employee’s address in the service record, with deemed service if undelivered and affixed on the office notice board – * Author 2370 [2024] 11 S.C.R. Supreme Court Reports Notices sent to the employee’s permanent address, with postal remarks indicating he had left his job and residence – Satisfied procedural requirements – Held that the employer’s actions complied with the regulation, and the employee’s non-response justified the abandonment finding – The High Court’s doubt on notice service was misplaced. [Paras 9, 11] Held: The High Court erred in granting relief to the employee by allowing the Writ Petition and setting aside the termination , as it overlooked that \"it was a case of the employee abandoning his services without informing his employer about his whereabouts\" – Treating the employee to have abandoned his service and taking appropriate action against him, in terms of the LIC Staff Regulation, cannot be faulted, given his absence since 25.09.1995, unanswered notices, and subsequent employment with the Food Corporation of India on 14.04.1997 – The employee’s suppression of this employment in his Writ Petition filed on 05.01.1998 disentitled him to equitable relief from the High Court in exercise of powers under Article 226 of the Constitution – Accordingly, the impugned is set aside and quashed [Paras 8-13]. List of Acts Constitution of India; LIC Staff Regulations, 1960. List of Keywords Abandonment of service; Unauthorized absence; Equitable relief; Suppression of facts. Case Arising From CIVIL APPELLATE JURISDICTION : Civil Appeal No. 4393 of 2010 From the and dated 26.06.2008 of the High Court of H.P at Shimla in LPA No. 6 of 2003 Appearances for Parties Kailash Vasudev, Sr.\n",
      "\n",
      "[Confidence=0.47]\n",
      "SINGH v. PUNJAB NATIONAL BANK 899 last known address calling upon the employee to report for duty within 30 days of the notice stating inter alia, the grounds for the management coming to the conclusion that the employee has no intention of joining duties and furnishing necessary evidence, wherever available. Unless the employee reports for duty within 30 days or unless he gives an explanation for his absence satisfying the management that he has not taken up another employment for avocation and that he has no intention of not joining duties, the employee will be deemed to have voluntarily retired from the Bank’s service on the expiry of the said notice. In the event of employee submitting a satisfactory reply, he shall be permitted to report for duty thereafter within 30 days from the date of the expiry of the aforesaid notice without prejudice to the banks right to take any action under law or rules of service.” 10. A person aggrieved by the of transfer cannot sit at home and decide on his own that the is illegal or erroneous and he will not comply with the same. If the workman had any grievance, he could have availed of his remedy available against the same; otherwise, he was duty-bound to comply with the same. Failure to avail of any remedy also would mean that he had accepted the and was duty-bound to comply with the same. At a later stage, he could not take a plea that the being erroneous, no consequence would follow for its non-compliance. 11. On 20.12.1983, a letter was issued to the workman reminding him that despite his transfer to the Branch Offi ce, Bhagwantnagar, Unnao, he had not yet reported for duty. He was given ten days’ time to report for duty or latest by 05.01.1984. It was stated that otherwise, it shall be presumed that he was absenting unauthorisedly and disciplinary action would be taken against him in terms of the Bipartite Agreement. This was followed by another letter dated 05.01.1984. The workman was given ten days’ time to join the duty from the date of receipt of the letter or latest by 20.01.1984, whichever was earlier. Further, the intention of the workman was quite evident from the subsequent events which remained undisputed, namely, that he intended to join legal practice which he did, as admittedly in the year 1985, he got himself enrolled as an Advocate and is in active practice. The communication dated 30.01.1984 from the Bank to the workman shows that the workman had personally submitted a letter dated 24.01.1984 to the 900 SUPREME COURT REPORTS [2023] 15 S.C.R. Regional Manager, Lucknow Region of the Bank. As per the direction of the Bank, the workman was given time upto 06.02.1984 for reporting for duty. It is evident from the communication dated 01.02.1984 addressed by the workman to the Bank that he was in the knowledge of all the developments and further, being a Law Graduate, he very well knew the consequences of failure to challenge an and not complying with the same.\n",
      "\n",
      "\n",
      "Now respond in EXACTLY this structure:\n",
      "\n",
      "1. Key Legal Issues Raised\n",
      "2. Possible Applicable Acts / IPC / CrPC / Labour Codes\n",
      "3. How Supreme Court Has Handled Similar Cases\n",
      "4. General Strategic Considerations (Non-advisory)\n",
      "5. Potential Risks / Limitations\n",
      "6. Documentation Commonly Required in Such Matters\n",
      "7. Strong Disclaimer (Not Legal Advice)\n",
      "\n",
      "Start now:\n",
      "ORUMORUMUMsgedged “FAUM’FADUMUMUMORUM, andions’orumsums’ and\n",
      "ORORORSEs or ORVE:ORGEs: and “AND:\n",
      "1:\n",
      "Ording “FA: FA: and “and: F:\n",
      "Commence: Case:\n",
      "2: Claumsums’s “AND “FASSUM’ and “FA’and “2 and “and “AND “FAUMOR’provance’sums’MINLYsuring “ANDs ANDs and ANDs’s AND received and confirmedised CO and been ANDised ORs AND OR “AND AND CO BEured and AND and “A:\n",
      "and “Re “acc, and “under INOR and with THEOROR and and BEMENTs and 2s and the and “conts: “11:\n",
      "and “under “under: “prov ‘prov:1:9:1: Case:\n",
      "case:\n",
      "under “\n",
      "Conf: Case:\n",
      "Confised, and “the7, Case case case, case, and ‘conts case “pro ‘pros, and “or “prov or or or or ORs, or “FA or or “Conf, orded, or “1.1 case/prov “Es “Re. Prem provided: Case/H/7119s/cont/prov/conts/prov ‘prov/1: to case/9 case “FA/to to to to to ‘ and “Case “prov “the “: Prem “the “prov “prov “the case “case: Prem: Premal: Prem:9s:\n"
     ]
    }
   ],
   "source": [
    "# Full RAG test flow inside notebook\n",
    "\n",
    "user_case = \"I was terminated from a private job without notice.\"\n",
    "\n",
    "retrieved = retrieve_chunks(user_case, top_k=3)\n",
    "prompt = build_legal_prompt(user_case, retrieved)\n",
    "\n",
    "response = generate_response(prompt, max_tokens=350)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976abc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'retrieve_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from legal_formatter import build_structured_prompt\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# from retrieve_chunks import retrieve_chunks\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# from generate_response import generate_response\u001b[39;00m\n\u001b[32m      5\u001b[39m user_case = \u001b[33m\"\u001b[39m\u001b[33mI was terminated from a private job without notice.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m chunks = \u001b[43mretrieve_chunks\u001b[49m(user_case, top_k=\u001b[32m5\u001b[39m)\n\u001b[32m      8\u001b[39m prompt = build_structured_prompt(user_case, chunks)\n\u001b[32m     10\u001b[39m response = generate_response(prompt)\n",
      "\u001b[31mNameError\u001b[39m: name 'retrieve_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# from legal_formatter import build_structured_prompt\n",
    "# from retrieve_chunks import retrieve_chunks\n",
    "# from generate_response import generate_response\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
